{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install rouge_score nltk absl-py transformers evaluate sentencepiece\n",
    "!pip3 install bleurt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"madhavappaneni/t5-small-chit-chat-conv\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    model_name, use_auth_token=\"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\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name, use_auth_token=\"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\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nighty night!'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_response(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    outputs = model.generate(input_ids,\n",
    "                             min_length=5,\n",
    "                             max_length=30,\n",
    "                             do_sample=True, num_beams=5, no_repeat_ngram_size=2)\n",
    "    generated_text = tokenizer.decode(\n",
    "        outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "generate_response(\"I'm headed off to sleep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6662, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_pickle('./datasets/test.pkl')\n",
    "\n",
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It's all good! I don't know.\", \"Well I'm going to church in about 20mins so I can't wait to go back home tonight! It's a\", \"I'm up to you. What's your favorite part about you? What do you like to do?\", \"Nice! I'm really excited to see you!\"]\n",
      "['I am doing really well thanks for asking Are you just relaxing or doing anything fun today?', 'Oh that is exciting! Yeah real quick then BYU did this so they can get conversation data to help improve AI units to be more capable of conversation Rather than just one party talking the whole time', 'Yeah its pretty cool I am just spending the next few hours relaxing', 'Yeah It is always nice to take a break I dont really ever take enough']\n"
     ]
    }
   ],
   "source": [
    "reference_sentences = []\n",
    "generated_sentences = []\n",
    "start = 1\n",
    "end = 5\n",
    "for index, row in test_df[start:end].iterrows():\n",
    "    input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "    generated_sentences.append(generate_response(input_text))\n",
    "    reference_sentences.append(label)\n",
    "\n",
    "print(generated_sentences)\n",
    "print(reference_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in range(67):\n",
    "    start_index = batch * 100\n",
    "    end_index = min(start_index + 100, 6662)\n",
    "    batch_data = test_df[start_index:end_index]\n",
    "    reference_sentences = []\n",
    "    generated_sentences = []\n",
    "    for index, row in batch_data.iterrows():\n",
    "        input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "        generated_sentences.append(generate_response(input_text))\n",
    "        reference_sentences.append(label)\n",
    "        df = pd.DataFrame({'reference_sentences': reference_sentences,\n",
    "                           'generated_sentences': generated_sentences})\n",
    "        df.to_pickle('./files/ref_gen_'+str(start_index)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "# num_batches = int(len(test_df) / batch_size)\n",
    "\n",
    "# for batch in range(num_batches):\n",
    "#     start_index = batch * batch_size\n",
    "#     end_index = min(start_index + batch_size, len(test_df))\n",
    "#     batch_data = test_df[start_index:end_index]\n",
    "#     reference_sentences = []\n",
    "#     generated_sentences = []\n",
    "#     for index, row in batch_data.iterrows():\n",
    "#         input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "#         generated_sentences.append(generate_response(input_text))\n",
    "#         reference_sentences.append(label)\n",
    "#     df = pd.DataFrame({'reference_sentences': reference_sentences,\n",
    "#                        'generated_sentences': generated_sentences})\n",
    "#     df.to_pickle(f'./files/ref_gen_{start_index}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df_list = []\n",
    "\n",
    "directory = './files/'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.pkl'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df_list.append(pd.read_pickle(filepath))\n",
    "\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.shape\n",
    "merged_df.to_pickle('./files/ref_gen_master.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_sentences</th>\n",
       "      <th>generated_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice! So you are planning on going to the part...</td>\n",
       "      <td>I'm glad you have a good day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haha, maybe you can find a girlfriend there. W...</td>\n",
       "      <td>Ya, it will be fun to meet up with all the peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What if it's a dude. I think what we could hav...</td>\n",
       "      <td>Haha yeah I think that would be a lot of fun. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>try it. It would be very casual, and she would...</td>\n",
       "      <td>I dont know what happened on the test. I feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As for the sixty eight, welcome to all of my c...</td>\n",
       "      <td>I asked her if she wanted to, but she was a girl.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 reference_sentences  \\\n",
       "0  Nice! So you are planning on going to the part...   \n",
       "1  Haha, maybe you can find a girlfriend there. W...   \n",
       "2  What if it's a dude. I think what we could hav...   \n",
       "3  try it. It would be very casual, and she would...   \n",
       "4  As for the sixty eight, welcome to all of my c...   \n",
       "\n",
       "                                 generated_sentences  \n",
       "0                      I'm glad you have a good day!  \n",
       "1  Ya, it will be fun to meet up with all the peo...  \n",
       "2  Haha yeah I think that would be a lot of fun. ...  \n",
       "3  I dont know what happened on the test. I feel ...  \n",
       "4  I asked her if she wanted to, but she was a girl.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_pickle('./files/ref_gen_master.pkl')\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242, 5242)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_sentences = list(merged_df['reference_sentences'])\n",
    "generated_sentences = list(merged_df['generated_sentences'])\n",
    "len(reference_sentences), len(generated_sentences)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLEU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU 1 0.06003306315565057\n",
      "BLEU 2 0.02191754049771865\n",
      "BLEU 3 0.00938591982855173\n",
      "BLEU 4 0.00125577823639605\n",
      "Average BLEU: 0.033898075429579252\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\", module_type=\"metric\")\n",
    "\n",
    "bleu1 = bleu.compute(predictions=generated_sentences,\n",
    "                     references=reference_sentences, max_order=1)\n",
    "bleu2 = bleu.compute(predictions=generated_sentences,\n",
    "                     references=reference_sentences, max_order=2)\n",
    "bleu3 = bleu.compute(predictions=generated_sentences,\n",
    "                     references=reference_sentences, max_order=3)\n",
    "bleu4 = bleu.compute(predictions=generated_sentences,\n",
    "                     references=reference_sentences, max_order=4)\n",
    "\n",
    "print('BLEU 1', bleu1['bleu'])\n",
    "print('BLEU 2', bleu2['bleu'])\n",
    "print('BLEU 3', bleu3['bleu'])\n",
    "print('BLEU 4', bleu4['bleu'])\n",
    "\n",
    "\n",
    "print('Average BLEU:', (bleu1['bleu'] +\n",
    "      bleu2['bleu'] + bleu3['bleu'] + bleu4['bleu'])/4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLEURT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No checkpoint specified, defaulting to BLEURT-tiny.\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Debolina\\AppData\\Roaming\\Python\\Python311\\site-packages\\bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "-0.693769249652053\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "scorer = score.BleurtScorer()\n",
    "scores = scorer.score(references=reference_sentences,\n",
    "                      candidates=generated_sentences)\n",
    "print(sum(scores)/len(scores))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT score (F1): 0.86\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "precision, recall, f1 = score(\n",
    "    generated_sentences, reference_sentences, lang='en', verbose=False)\n",
    "\n",
    "print(f\"BERT score (F1): {f1.mean().item():.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROUGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.24933682048335138,\n",
       " 'rouge2': 0.1533887263579505,\n",
       " 'rougeL': 0.10948814201314775,\n",
       " 'rougeLsum': 0.10945846065505774}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "rouge_score = rouge.compute(\n",
    "    predictions=generated_sentences, references=reference_sentences)\n",
    "rouge_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
